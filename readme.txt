# üß© TokenMate - Web Tokenizer

### A lightweight, customizable, and powerful web tokenizer that breaks down text into meaningful components for analysis and learning.

---

## ‚ú® Features

- **Custom Tokenization**: Split input text into words, numbers, punctuation, and more using a flexible tokenizer.
- **Granular Breakdown**: Visualize the detailed composition of your tokens down to the letter.
- **Smart Decimal Handling**: Keeps decimal numbers intact, preventing them from being split.
- **Real-Time Tokenization**: See token results as you type or paste text.
- **Intuitive UI/UX**: Easy-to-use, with handcrafted animations and thoughtfully curated components to enhance user experience.
- **No External Libraries**: Built from scratch without relying on third-party libraries, offering better control over customization.

---

## üìö How It Works

1. **Input your text** into the provided text area.
2. Click on the **"Tokenize My Text"** button.
3. **Phase 1**: The input is split into individual tokens and their types are displayed.
4. **Phase 2**: Each token is further broken down into its granular components (characters, spaces, punctuation, etc.).
5. **Semicolon Delimiter**: Use a semicolon `;` to separate phrases for tokenization.

---

## üöÄ Installation & Setup

To run TokenMate locally, follow these steps:

### 1. Clone the repository

```bash
git clone https://github.com/your-username/tokenmate.git
cd tokenmate

### 2. Open in your browser
Simply open the index.html file in any modern browser to get started.

## üåê Usage
Paste or type your text into the input field.
Click the "Tokenize My Text" button to see the output.
The results will be displayed in two phases:
Phase 1: Token type classification.
Phase 2: Granular character breakdown.

## üõ†Ô∏è Technologies
HTML5
CSS3 (with custom animations and handcrafted UI elements)
Vanilla JavaScript (No external libraries)

## ü§î Challenges Faced
As a group, we worked through the following challenges:

Front-end Struggles: Crafting an appealing and responsive user interface with smooth animations and user-friendly components proved to be tricky, especially when hand-coding everything from scratch.
No External Libraries: We intentionally avoided using third-party libraries, which increased the complexity of handling animations, tokenization logic, and UI/UX flows.
Decimal Tokenization: Handling edge cases like decimal numbers during tokenization was a challenge that required careful planning.

##üí° What We Learned
Collaboration: The importance of communicating ideas and solutions effectively.
Front-End Skills: Improved our understanding of creating smooth, hassle-free user experiences with custom animations and optimized code.
Manual Tokenization: How to build a tokenizer from scratch without relying on pre-existing libraries, giving us more control over how our tokens are processed.
Problem Solving: Overcoming front-end and back-end integration challenges, particularly around token parsing logic.
